{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j471MBKkydWg"
      },
      "source": [
        "# General Description:\n",
        "\n",
        "For CDD\n",
        "\n",
        "Plotting choice as a function of delay_amount, subdivded by delay_wait_time and immediate_amount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfWuNzSNytd9"
      },
      "source": [
        "Importing libraries and mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSm59xohy8tq",
        "outputId": "5b2f3601-0429-4955-d558-0f97ffa4871a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import os,sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# global parameters\n",
        "WAIT_DICT = {'now':0,'in 1 day': 1/30.0,'in 1 week':0.25,'in 1 month': 1, 'in 3 months':3, 'in 1 year': 12, 'in 3 months': 3, 'in 5 years':60}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbyLl34i1XVa"
      },
      "source": [
        "Defining count_tuples() function to return the unique items and their frequencies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resync_df(df):\n",
        "    print('Presync')\n",
        "    for c in list(df):\n",
        "        if ('amount' in c) or ('delay' in c):\n",
        "            if c == 'SS amount':\n",
        "                continue\n",
        "            tabulate_col(df,fn='/tmp',col=c,save=False,verbose=False)\n",
        "    df = df.rename(columns={'SS amount' : 'cdd_immed_amt','LL amount':'cdd_delay_amt','SS delay':'cdd_immed_wait','LL delay':'cdd_delay_wait','Response [-1O_0I_1D]':'cdd_choice'})\n",
        "    for c in ['cdd_immed_amt','cdd_delay_amt']:\n",
        "        df[c] = df[c].map(lambda x: x.lstrip('gain $').replace(',','')).astype(int)\n",
        "    df = df.drop(columns=['Stimulus onset','Response time','Now loc [0L_1R]'])\n",
        "    for c in ['cdd_immed_wait','cdd_delay_wait']:\n",
        "        df[c] = df[c].map(WAIT_DICT)\n",
        "    return df\n",
        "    \n",
        "def count_tuples(listA):\n",
        "    unique_items = list(set(listA))\n",
        "    item_count = [listA.count(item) for item in unique_items]\n",
        "    return unique_items,item_count\n",
        "  \n",
        "def tabulate_col(df,fn='/tmp/',col='cdd_immed_amt',save=False,verbose=True):\n",
        "    count_df = df[col].value_counts().sort_index()\n",
        "    count_df = count_df.reset_index()\n",
        "    if verbose:\n",
        "        print(count_df)\n",
        "    #create .csv file with this info\n",
        "    if save:\n",
        "        print(\"Saving to: {}\".format(fn))\n",
        "        count_df.to_csv(fn)\n",
        "\n",
        "def sync_and_save(split_dir,fn,cols=[],header=0,save=False):\n",
        "    try:\n",
        "        df = pd.read_csv(fn,header=header)\n",
        "    except Exception as e:\n",
        "        print('We got an Exception: {}'.format(e))\n",
        "        print('We will move on the next spreadsheet')\n",
        "        return\n",
        "\n",
        "    subj_crdm_dir = os.path.join(split_dir,get_subject(fn),'crdm')\n",
        "    if not os.path.exists(subj_crdm_dir):\n",
        "        os.makedirs(subj_crdm_dir)\n",
        "    df = resync_df(df)\n",
        "\n",
        "\"\"\"     for col in cols:\n",
        "        fn = os.path.join('csv','{}.csv'.format(col))\n",
        "        tabulate_col(df,fn=fn,col=col,save=save)\n",
        " \"\"\"\n",
        "\n",
        "def get_subject(fn):\n",
        "    fileparts = os.path.basename(fn).split('_')\n",
        "    subj = '_'.join(fileparts[1:3])\n",
        "    return subj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/002/AdjAmt_002_1_10-26-2017_14h-59m.csv\n",
            "We got an Exception: Error tokenizing data. C error: Expected 7 fields in line 47, saw 8\n",
            "\n",
            "We will move on the next spreadsheet\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/002/AdjAmt_002_1_10-26-2017_16h-57m.csv\n",
            "Subject is 002_1\n",
            "Presync\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/002/AdjAmt_002_2_11-20-2017_13h-24m.csv\n",
            "We got an Exception: Error tokenizing data. C error: Expected 7 fields in line 47, saw 8\n",
            "\n",
            "We will move on the next spreadsheet\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/002/AdjAmt_002_2_11-20-2017_15h-19m.csv\n",
            "Subject is 002_2\n",
            "Presync\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/109/AdjAmt_109_1_11-03-2022_13h-47m.csv\n",
            "We got an Exception: Error tokenizing data. C error: Expected 7 fields in line 47, saw 8\n",
            "\n",
            "We will move on the next spreadsheet\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/109/AdjAmt_109_1_11-03-2022_15h-57m.csv\n",
            "Subject is 109_1\n",
            "Presync\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/109/AdjAmt_109_2_12-20-2022_13h-34m.csv\n",
            "We got an Exception: Error tokenizing data. C error: Expected 7 fields in line 47, saw 8\n",
            "\n",
            "We will move on the next spreadsheet\n",
            "Working on file: /Volumes/UCDN/datasets/DDT/raw_csv/109/AdjAmt_109_2_12-20-2022_15h-16m.csv\n",
            "Subject is 109_2\n",
            "Presync\n"
          ]
        }
      ],
      "source": [
        "raw_csv_dir = '/Volumes/UCDN/datasets/DDT/raw_csv/'\n",
        "split_dir = '/Volumes/UCDN/datasets/DDT/split/'\n",
        "cols = ['cdd_immed_wait','cdd_delay_amt','cdd_delay_wait','cdd_immed_amt']\n",
        "\n",
        "#get set of all good data files for analysis\n",
        "good_files = sorted(glob(os.path.join(raw_csv_dir, '*/AdjAmt*.csv')))\n",
        "if (not good_files):\n",
        "    print(\"No good files available. Check file path.\")\n",
        "    sys.exit()\n",
        "\n",
        "for i, subj_fn in enumerate(good_files):\n",
        "    print('Working on file: {}'.format(subj_fn))\n",
        "    sync_and_save(split_dir,subj_fn,cols=cols,header=4,save=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

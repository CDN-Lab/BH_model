{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hierarchical Model (BHM) \n",
    "\n",
    "Parameter estimation written for CRDM task as part of the IDM dataset collected online with Mturk\n",
    "\n",
    "Extended to work for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in/Generic Imports\n",
    "import os,sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the name of the directory\n",
    "# where the this file is present.\n",
    "# current = os.path.dirname(os.path.realpath(__file__))\n",
    "current = os.path.dirname(os.getcwd())\n",
    " \n",
    "# Getting the parent directory name\n",
    "# where the current directory is present.\n",
    "# parent = os.path.dirname(os.path.dirname(current))\n",
    "# parent = current\n",
    "parent = '/Users/pizarror/IDM'\n",
    "# print(parent)\n",
    "#/Users/pizarror/IDM\n",
    "\n",
    "# adding the parent directory to\n",
    "# the sys.path.\n",
    "sys.path.append(parent)\n",
    "\n",
    "from IDM_model.src import model_functions as mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load_data(subject='23_IDM_0144',fn='/tmp',domain='gain',cols=[]):\n",
    "    crdm_df = pd.read_csv(fn)\n",
    "    task='crdm'\n",
    "    if ('loss' in domain) or ('combined' in domain):\n",
    "        if 'loss' not in crdm_df['crdm_domain'].dropna().unique():\n",
    "            return []\n",
    "\n",
    "    if ('loss' in domain) or ('gain' in domain):\n",
    "        # only select by domain when gain or loss\n",
    "        crdm_df = mf.get_by_domain(crdm_df,domain=domain,task=task,verbose=False)\n",
    "    crdm_df = mf.drop_pract(crdm_df,task=task)\n",
    "    crdm_df,response_rate = mf.drop_non_responses(crdm_df,task=task,verbose=False) \n",
    "    data = mf.get_data(crdm_df,cols,task='crdm')[0]\n",
    "    data['subject'] = subject\n",
    "    return data \n",
    "\n",
    "def diganostic_plots(trace,experiment='experiment',utility_dir='/tmp/',subject='23_IDM_0001',task='crdm',coords={},var_names=['alpha','beta','gamma'],figsize=(10,10)):\n",
    "\n",
    "    bh_dir = os.path.join(utility_dir,subject,task,'bh')\n",
    "    if not os.path.exists(bh_dir):\n",
    "        os.makedirs(bh_dir)\n",
    "    print('Saving diagnostic plots to bh_dir : {}'.format(bh_dir))\n",
    "\n",
    "    title_dict = {'fontsize':15}\n",
    "\n",
    "    # 2by2 : rows 2 varialbes, cols 2 for distribution and sampled values\n",
    "    axes = az.plot_trace(trace, var_names=var_names,coords=coords,compact=False)\n",
    "    for r in range(axes.shape[0]):\n",
    "        for c in range(axes.shape[1]):\n",
    "            axes[r,c].set_title('{}: {}'.format(subject,var_names[r]))\n",
    "    plt.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_trace_plot.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "    \n",
    "    axes = az.plot_pair(trace,kind='kde', coords=coords,var_names=var_names,marginals=True)\n",
    "    axes[0,0].set_title(subject,fontdict=title_dict)\n",
    "    axes[1,0].set_ylabel(var_names[1])\n",
    "    axes[1,0].set_xlabel(var_names[0])\n",
    "    plt.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_bivariate_densities.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "    \n",
    "    axes = az.plot_posterior(trace,var_names=var_names,coords=coords)\n",
    "    # print(axes.shape)\n",
    "    for c in range(axes.shape[0]):\n",
    "        axes[c].set_title('{}: {}'.format(subject,var_names[c]),fontdict=title_dict)\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_posterior.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(var_names), figsize=figsize)\n",
    "    az.plot_rank(trace,var_names=var_names,coords=coords,ax=axes)\n",
    "    for c in range(axes.shape[0]):\n",
    "        axes[c].set_title('{}: {}'.format(subject,var_names[c]),fontdict=title_dict)\n",
    "    fig.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_rank_plot_bars.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(var_names), figsize=figsize)\n",
    "    axes = az.plot_rank(trace,var_names=var_names, coords=coords,kind=\"vlines\",vlines_kwargs={'lw':0}, marker_vlines_kwargs={'lw':3},ax=axes)\n",
    "    for c in range(axes.shape[0]):\n",
    "        axes[c].set_title('{}: {}'.format(subject,var_names[c]),fontdict=title_dict)\n",
    "    fig.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_rank_plot_lines.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We will load the data from all participants so we can run the modeling schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirs_and_data(root_dir='/tmp',dataset='IDM',domain='gain'):\n",
    "\n",
    "    dataset_dir = os.path.join(root_dir,dataset)\n",
    "    split_dir = os.path.join(dataset_dir,'split')\n",
    "    utility_dir = os.path.join(dataset_dir,'utility')\n",
    "    save_dir = os.path.join(utility_dir,'BHM/crdm')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Takes about 10 seconds for 149 subjects form Mturk data\n",
    "    task = 'crdm'\n",
    "    subjs = sorted(glob.glob(os.path.join(split_dir,'*')))\n",
    "    cols = ['crdm_choice','crdm_sure_p','crdm_lott_p','crdm_sure_amt','crdm_lott_amt','crdm_amb_lev']\n",
    "    data = pd.DataFrame(columns=['subject']+cols)\n",
    "    subj_id = 0\n",
    "    for s in subjs:\n",
    "        subject = os.path.basename(s)\n",
    "        fn  = os.path.join(s,task,'{}_{}.csv'.format(os.path.basename(s),task))\n",
    "        if os.path.exists(fn):\n",
    "            subj_data = read_load_data(subject=subject,fn=fn,domain=domain,cols=cols)\n",
    "            if subj_data.empty:\n",
    "                continue\n",
    "            for c in cols:\n",
    "                subj_data[c] = subj_data[c].astype(float)        \n",
    "            subj_data['subject_id'] = int(subj_id)\n",
    "            subj_id = subj_id+1\n",
    "            data = pd.concat([data,subj_data],ignore_index=True)\n",
    "\n",
    "    return utility_dir,save_dir,data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cols(data):\n",
    "    subjects = data['subject'].unique()\n",
    "    # nb_subj = subjects.shape[0]\n",
    "    # nb_trials = data.shape[0]//nb_subj\n",
    "    subj_id_list = data['subject_id'].to_list()\n",
    "    subj_id = [int(s) for s in subj_id_list]\n",
    "    # old_id = np.array([ [s]*nb_trials for s in range(nb_subj) ]).flatten()\n",
    "\n",
    "    sure_p = data['crdm_sure_p'].values\n",
    "    lott_p = data['crdm_lott_p'].values\n",
    "    sure_amt = data['crdm_sure_amt'].values\n",
    "    lott_amt = data['crdm_lott_amt'].values\n",
    "    ambig = data['crdm_amb_lev'].values\n",
    "    choices = data['crdm_choice'].values\n",
    "    \n",
    "    return subjects,subj_id,sure_p,lott_p,sure_amt,lott_amt,ambig,choices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Hierarchical Model\n",
    "\n",
    "Developed under parameter receovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amplitude(amt):\n",
    "    return np.divide(amt,np.abs(amt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_BHM(save_dir,experiment,domain,data):\n",
    "    \n",
    "    subjects,subj_id,sure_p,lott_p,sure_amt,lott_amt,ambig,choices = extract_cols(data)\n",
    "    # amplitude parameter to handle gain and loss\n",
    "    sure_amp = get_amplitude(sure_amt)\n",
    "    lott_amp = get_amplitude(lott_amt)\n",
    "\n",
    "    tStep1 = time.time()\n",
    "\n",
    "    # We will fit a model for each subject\n",
    "    with pm.Model() as model_simple:\n",
    "\n",
    "        # Hyperparameters for alpha, beta\n",
    "        mu_alpha_hyper = pm.Normal('mu_alpha_hyper',mu=-0.635,sigma=0.05)\n",
    "        sd_alpha_hyper = pm.Normal('sd_alpha_hyper',mu=0.418,sigma=0.01)\n",
    "\n",
    "        mu_beta_hyper = pm.Normal('mu_beta_hyper',mu=0.254,sigma=0.05)\n",
    "        sd_beta_hyper = pm.Normal('sd_beta_hyper',mu=0.575,sigma=0.01)\n",
    "        \n",
    "        # mu_gamma_hyper = pm.Normal('mu_gamma_hyper',mu=3.011,sigma=0.05)\n",
    "        sd_gamma_hyper = pm.Normal('sd_gamma_hyper',mu=2.046,sigma=0.01)\n",
    "\n",
    "        alpha = pm.LogNormal('alpha',mu=mu_alpha_hyper, sigma=sd_alpha_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        beta = pm.Normal('beta',mu=mu_beta_hyper,sigma=sd_beta_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        gamma = pm.HalfNormal('gamma',sigma=sd_gamma_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        \n",
    "        prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * \n",
    "                                                                (lott_amp*(np.abs(lott_amt)**alpha[subj_id])*(lott_p-beta[subj_id]*ambig/2)\n",
    "                                                                - sure_amp*(np.abs(sure_amt)**alpha[subj_id])*sure_p)))) \n",
    "        \n",
    "        y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "        # trace_prior = pm.sample(100, tune=20, cores=2,target_accept=0.95,progressbar=True)\n",
    "        trace_prior = pm.sample(10000, tune=1000, cores=5,target_accept=0.99,progressbar=True)\n",
    "\n",
    "\n",
    "    summary= az.summary(trace_prior,round_to=10)\n",
    "    fn = os.path.join(save_dir,'BHM_model_summary_{}_{}.csv'.format(experiment,domain))\n",
    "    print('Saving to : {}'.format(fn))\n",
    "    summary.to_csv(fn)\n",
    "\n",
    "    fn = os.path.join(save_dir,'BHM_model_trace_{}_{}.pkl'.format(experiment,domain))\n",
    "    print('Saving to : {}'.format(fn))\n",
    "    with open(fn,'wb') as buff:\n",
    "        pickle.dump({'trace':trace_prior},buff)\n",
    "\n",
    "    print('Time to complete {} aggregate BHM : {} minutes'.format(len(subjects),(time.time() - tStep1)/60.0))\n",
    "    return trace_prior,subjects,subj_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean(fn,var_names=['alpha','beta','gamma'],subjects=[],domain='gain'):\n",
    "    nb_subjects = len(subjects)\n",
    "    df = pd.read_csv(fn,index_col=0)\n",
    "    df_bhm = pd.DataFrame([],columns=var_names)\n",
    "    df_bhm['subject'] = subjects\n",
    "    df_bhm['domain'] = domain\n",
    "    for var in var_names:\n",
    "        ind_list = ['{}[{}]'.format(var,sub_id) for sub_id in range(nb_subjects)]\n",
    "        df_bhm[var] = df.loc[df.index.isin(ind_list)]['mean'].reset_index(drop=True)\n",
    "    return df_bhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='11776' class='' max='55000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      21.41% [11776/55000 00:20&lt;01:16 Sampling 5 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the paths needed to find the data and load\n",
    "\n",
    "# The user of the script can edit root_dir and dataset variables to get it to work for their dataset.\n",
    "# This script will work given the data is stored in the appropriate BIDS format in the split directory\n",
    "root_dir = '/Volumes/UCDN/datasets/'\n",
    "dataset = 'SDM'\n",
    "\n",
    "# log the BHM experiment version, in case we cahnge it in the future\n",
    "experiment='v002'\n",
    "\n",
    "for domain in ['gain','loss','combined']:\n",
    "    utility_dir,save_dir,data = dirs_and_data(root_dir=root_dir,dataset=dataset,domain=domain)\n",
    "    if data.empty:\n",
    "        # catch for when CRDM data by domain is not present\n",
    "        continue\n",
    "    trace_prior,subjects,subj_id = run_BHM(save_dir,experiment,domain,data)\n",
    "    \n",
    "    bhm_fn = os.path.join(save_dir,'BHM_model_summary_{}_{}.csv'.format(experiment,domain))\n",
    "    df_bhm = extract_mean(bhm_fn,var_names=['alpha','beta','gamma'],subjects=subjects,domain=domain)    \n",
    "    split_CRDM_fn = os.path.join(os.path.dirname(save_dir),'split_CRDM_BHM_{}.csv'.format(domain))\n",
    "    print('Saving split BHM : {}'.format(split_CRDM_fn))\n",
    "    df_bhm.to_csv(split_CRDM_fn)\n",
    "    display(df_bhm)\n",
    "    for s in set(subj_id):\n",
    "        coords={'alpha_dim_0': [s],'beta_dim_0': [s],'gamma_dim_0':[s]}\n",
    "        diganostic_plots(trace_prior,experiment=experiment,utility_dir=utility_dir,subject=subjects[s],coords=coords,var_names=['alpha','beta','gamma'],figsize=(10,10))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract parameter estimates and save\n",
    "\n",
    "We can incorporate this into the script above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic plots\n",
    "\n",
    "Too many subjects to run `diagnistic_plots()`  but can run them individually\n",
    "Trace, posterior, rank plots\n",
    "\n",
    "... need to figure out for each subject how to plot_pair() which plots the bivariate distirbutions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d5eda77765311109b2c027e144dcf58f89dd96008cdf29c2e6b03e99df71a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

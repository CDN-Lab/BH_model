{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing results\n",
    "\n",
    "We are trying a lot of different things. Let's log the attempts to share with others\n",
    "\n",
    "The scripts here will NOT work. We are just keeping track of what we are trying and what is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter recovery : v002\n",
    "\n",
    "actively trying by loosening the variance but enforcing with a bound so we don't get negative variance ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bhm(subj_id=[],design_df=[],choices=[],type='single'):\n",
    "\n",
    "    delay_amt = design_df['cdd_delay_amt'].values\n",
    "    delay_wait = design_df['cdd_delay_wait'].values\n",
    "    immed_amt = design_df['cdd_immed_amt'].values\n",
    "    immed_wait = design_df['cdd_immed_wait'].values\n",
    "    \n",
    "    # We will fit a model for each subject\n",
    "    with pm.Model() as model_simple:\n",
    "\n",
    "        # Hyperparameters for kappa and gamma\n",
    "        # bound on both variance of kappa and gamma\n",
    "        BoundNormal = pm.Bound(pm.Normal, lower=0.05)\n",
    "        # estimated from MLE approximations : np.exp(-3.60) = 0.0273, np.sqrt(1.71)=1.308\n",
    "        mu_kappa_hyper = pm.Beta('mu_kappa_hyper',mu=np.exp(-3.60),sigma=0.01)\n",
    "        sd_kappa_hyper = BoundNormal('sd_kappa_hyper',mu=np.sqrt(1.71),sigma=0.5)\n",
    "        # estimated from MLE approximations : np.sqrt(2.30) = 1.517\n",
    "        sd_gamma_hyper = BoundNormal('sd_hyper',mu=np.sqrt(2.30),sigma=0.5)\n",
    "\n",
    "        kappa = pm.LogNormal('kappa',mu=mu_kappa_hyper,sigma=sd_kappa_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        gamma = pm.HalfNormal('gamma',sigma=sd_gamma_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        \n",
    "        prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait)) \n",
    "                                                                                - immed_amt/(1+(kappa[subj_id]*immed_wait)) ))))\n",
    "\n",
    "        y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "        trace_prior = pm.sample(10000, tune=1000, cores=5,target_accept=0.99,progressbar=False)\n",
    "\n",
    "    # This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "    summary= az.summary(trace_prior,round_to=10)\n",
    "    if type=='single':\n",
    "        kappa_hat = summary['mean'].loc['kappa[{}]'.format(0)]\n",
    "        gamma_hat = summary['mean'].loc['gamma[{}]'.format(0)]\n",
    "    elif type=='aggregate':\n",
    "        kappa_hat = [summary['mean'].loc['kappa[{}]'.format(x)] for x in set(subj_id)]\n",
    "        gamma_hat = [summary['mean'].loc['gamma[{}]'.format(x)] for x in set(subj_id)]\n",
    "    return kappa_hat,gamma_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter recovery : v001\n",
    "\n",
    "After Silvia and the CASANDRE meeting, we used the results of the MLE on the IDM dataset to come up with a prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kappa vs gamma MLE on IDM](img/mturk_all_CDD_kappa_gamma_scatter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bhm(subj_id=[],design_df=[],choices=[],type='single'):\n",
    "\n",
    "    delay_amt = design_df['cdd_delay_amt'].values\n",
    "    delay_wait = design_df['cdd_delay_wait'].values\n",
    "    immed_amt = design_df['cdd_immed_amt'].values\n",
    "    immed_wait = design_df['cdd_immed_wait'].values\n",
    "    \n",
    "    # We will fit a model for each subject\n",
    "    with pm.Model() as model_simple:\n",
    "\n",
    "        # Hyperparameters for kappa and gamma\n",
    "        # estimated from MLE approximations : np.exp(-3.60) = 0.0273, np.sqrt(1.71)=1.308\n",
    "        mu_kappa_hyper = pm.Beta('mu_kappa_hyper',mu=np.exp(-3.60),sigma=0.01)\n",
    "        sd_kappa_hyper = pm.Normal('sd_kappa_hyper',mu=np.sqrt(1.71),sigma=0.1)\n",
    "        # estimated from MLE approximations : np.sqrt(2.30) = 1.517\n",
    "        sd_gamma_hyper = pm.Normal('sd_hyper',mu=np.sqrt(2.30),sigma=0.1)\n",
    "\n",
    "        kappa = pm.LogNormal('kappa',mu=mu_kappa_hyper,sigma=sd_kappa_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        gamma = pm.HalfNormal('gamma',sigma=sd_gamma_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        \n",
    "        prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait)) \n",
    "                                                                                - immed_amt/(1+(kappa[subj_id]*immed_wait)) ))))\n",
    "\n",
    "        y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "        trace_prior = pm.sample(10000, tune=1000, cores=5,target_accept=0.99,progressbar=False)\n",
    "\n",
    "    # This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "    summary= az.summary(trace_prior,round_to=10)\n",
    "    if type=='single':\n",
    "        kappa_hat = summary['mean'].loc['kappa[{}]'.format(0)]\n",
    "        gamma_hat = summary['mean'].loc['gamma[{}]'.format(0)]\n",
    "    elif type=='aggregate':\n",
    "        kappa_hat = [summary['mean'].loc['kappa[{}]'.format(x)] for x in set(subj_id)]\n",
    "        gamma_hat = [summary['mean'].loc['gamma[{}]'.format(x)] for x in set(subj_id)]\n",
    "    return kappa_hat,gamma_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter recovery : v000\n",
    "\n",
    "gHNorm_kLogNorm_shareSD\n",
    "gamma HalfNormal, kappa LogNormal, shared LogNormal SD\n",
    "\n",
    "The priors are defined below but the biggest feature is sahring the hyper prior for the SD of both gamma and kappa. Intuitively this does not make sense but it was working when compared to MLE.\n",
    "\n",
    "I started developing BHM by estimating the parameters on the IDM dataset and comparing them to the MLE. This got me pretty far but discussing with Dr. Lopez, I realized I needed to develop BHM separately with a parameter recovery. This was a good start but now I can properly assess BHM to MLE with the parameter recovery pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gamma BHM to MLE](img/gamma-gHNorm_kLogNorm_shareSD.png)\n",
    "\n",
    "![kappa BHM to MLE](img/kappa-gHNorm_kLogNorm_shareSD.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bhm(subj_id=[],design_df=[],choices=[],type='single'):\n",
    "\n",
    "    delay_amt = design_df['cdd_delay_amt'].values\n",
    "    delay_wait = design_df['cdd_delay_wait'].values\n",
    "    immed_amt = design_df['cdd_immed_amt'].values\n",
    "    immed_wait = design_df['cdd_immed_wait'].values\n",
    "    \n",
    "    # We will fit a model for each subject\n",
    "    with pm.Model() as model_simple:\n",
    "\n",
    "        # Hyperparameters for kappa\n",
    "        mu_kappa_hyper = pm.Beta('mu_kappa_hyper',mu=0.02,sigma=0.01)\n",
    "        # use the same hyper SD for both parameters\n",
    "        sd_hyper = pm.LogNormal('sd_hyper',sigma=1)\n",
    "\n",
    "        kappa = pm.LogNormal('kappa',mu=mu_kappa_hyper,sigma=sd_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        gamma = pm.HalfNormal('gamma',sigma=sd_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        \n",
    "        prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait)) \n",
    "                                                                                - immed_amt/(1+(kappa[subj_id]*immed_wait)) ))))\n",
    "\n",
    "        y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "        trace_prior = pm.sample(10000, tune=1000, cores=5,target_accept=0.99,progressbar=False)\n",
    "\n",
    "    # This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "    summary= az.summary(trace_prior,round_to=10)\n",
    "    if type=='single':\n",
    "        kappa_hat = summary['mean'].loc['kappa[{}]'.format(0)]\n",
    "        gamma_hat = summary['mean'].loc['gamma[{}]'.format(0)]\n",
    "    elif type=='aggregate':\n",
    "        kappa_hat = [summary['mean'].loc['kappa[{}]'.format(x)] for x in set(subj_id)]\n",
    "        gamma_hat = [summary['mean'].loc['gamma[{}]'.format(x)] for x in set(subj_id)]\n",
    "    return kappa_hat,gamma_hat"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

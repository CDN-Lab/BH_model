{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing results\n",
    "\n",
    "We are trying a lot of different things. Let's log the attempts to share with others\n",
    "\n",
    "The scripts here will NOT work. We are just keeping track of what we are trying and what is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter recovery : v001 \n",
    "\n",
    "gHNorm_kLogNorm_shareSD\n",
    "gamma Halfnormal\n",
    "\n",
    "\n",
    "The priors are defined below but the biggest feature is sahring the hyper prior for the SD of both gamma and kappa. Intuitively this does not make sense but it was working when compared to MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bhm(subj_id=[],design_df=[],choices=[],type='single'):\n",
    "\n",
    "    delay_amt = design_df['cdd_delay_amt'].values\n",
    "    delay_wait = design_df['cdd_delay_wait'].values\n",
    "    immed_amt = design_df['cdd_immed_amt'].values\n",
    "    immed_wait = design_df['cdd_immed_wait'].values\n",
    "    \n",
    "    # We will fit a model for each subject\n",
    "    with pm.Model() as model_simple:\n",
    "\n",
    "        # Hyperparameters for kappa\n",
    "        mu_kappa_hyper = pm.Beta('mu_kappa_hyper',mu=0.02,sigma=0.01)\n",
    "        # use the same hyper SD for both parameters\n",
    "        sd_hyper = pm.LogNormal('sd_hyper',sigma=1)\n",
    "\n",
    "        kappa = pm.LogNormal('kappa',mu=mu_kappa_hyper,sigma=sd_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        gamma = pm.HalfNormal('gamma',sigma=sd_hyper,shape=np.size(np.unique(subj_id)))\n",
    "        \n",
    "        prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait)) \n",
    "                                                                                - immed_amt/(1+(kappa[subj_id]*immed_wait)) ))))\n",
    "\n",
    "        y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "        trace_prior = pm.sample(10000, tune=1000, cores=5,target_accept=0.99,progressbar=False)\n",
    "\n",
    "    # This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "    summary= az.summary(trace_prior,round_to=10)\n",
    "    if type=='single':\n",
    "        kappa_hat = summary['mean'].loc['kappa[{}]'.format(0)]\n",
    "        gamma_hat = summary['mean'].loc['gamma[{}]'.format(0)]\n",
    "    elif type=='aggregate':\n",
    "        kappa_hat = [summary['mean'].loc['kappa[{}]'.format(x)] for x in set(subj_id)]\n",
    "        gamma_hat = [summary['mean'].loc['gamma[{}]'.format(x)] for x in set(subj_id)]\n",
    "    return kappa_hat,gamma_hat"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

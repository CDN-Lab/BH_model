{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m genfromtxt\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[0;32m----> 7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpymc3\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpm\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39marviz\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39maz\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatistics\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mstats\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymc3'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd \n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "# import theano.tensor as tt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------------------------------------##\n",
    "##                             Import                               ##\n",
    "##  I did a pretty in-depth walkthrough of the BHM code in the      ##\n",
    "##  methods document, so I won't go into as much detail here about  ##\n",
    "##  the overall scheme. Instead, I'll be annotating lines to        ##\n",
    "##  clarify what they specifically do. I'll also put brief          ##\n",
    "##  explanatory bits at the top as necessary.                       ##\n",
    "##------------------------------------------------------------------##\n",
    "\n",
    "# For parameter recovery: \"Full Square\\FAKE RANDOMIZED Full Subjective Value Table Full Square With Generated Choices.csv\"\n",
    "# This can intake any data in a form similar to the Full Subjective Value Table\n",
    "data = genfromtxt(\"Full Subjective Value Table.csv\", delimiter=',', dtype=str)\n",
    "\n",
    "# Column titles: Trial Number\tStimulus Time\tResponse Time\tSS amount\tLL amount\tSS delay\tLL delay\tResponse\tSS SV\tLL SV\tk\tbeta\tID\tDay\tDate\tTime\tLL\tAIC\tBIC\tr2\tcorrect percent\n",
    "IDs = np.array(data[1:,12])\n",
    "Days = np.array(data[1:,13])\n",
    "Dates = np.array(data[1:,14])\n",
    "Times = np.array(data[1:,15])\n",
    "\n",
    "# Each participant session can be uniquely identified by a combination of ID, day, date, and time. This concatenates them all.\n",
    "Identifiers = np.array([i + j + k + l for i, j, k, l in zip(IDs, Days, Dates, Times)])\n",
    "\n",
    "# Note: these are all brought in as strings from genfromtext. It is critical to convert them to floats.\n",
    "SSAmount = np.array(data[1:,3], dtype=float)\n",
    "SSDelay = np.array(data[1:,5], dtype=float)\n",
    "LLAmount = np.array(data[1:,4], dtype=float)\n",
    "LLDelay = np.array(data[1:,6], dtype=float)\n",
    "Choices = np.array(data[1:,7], dtype=int)\n",
    "\n",
    "# These are the betas and kappas from MLE. These lines can be used to compare MLE to BHM.\n",
    "Betas = np.array(data[1:,11], dtype=float)\n",
    "Kappas = np.array(data[1:,10], dtype=float)\n",
    "\n",
    "# This will select only the non-catch trials.\n",
    "boolselector = (SSAmount<1000)*(LLDelay>0)\n",
    "\n",
    "IDs = IDs[boolselector]\n",
    "Days = Days[boolselector]\n",
    "Dates = Dates[boolselector]\n",
    "Times = Times[boolselector]\n",
    "Identifiers = Identifiers[boolselector]\n",
    "SSAmount = SSAmount[boolselector]\n",
    "SSDelay = SSDelay[boolselector]\n",
    "LLAmount = LLAmount[boolselector]\n",
    "LLDelay = LLDelay[boolselector]\n",
    "Choices = Choices[boolselector]\n",
    "Betas = Betas[boolselector]\n",
    "Kappas = Kappas[boolselector]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I put a full explanation of the idea behind this groups array in the methods document. I'll annotate the code here, but for information on the goal and general idea behind this, check out that document.\n",
    "\n",
    "# Array equivalent in size to IDs (arbitrary choice - could be Betas or LLAmount or anything; all the same size). Fill with ridiculous number for now so it'll throw errors later if the groups array isn't populated right.\n",
    "groups = np.full(len(IDs),100000)\n",
    "alreadycoded = []\n",
    "indextocount = 0\n",
    "\n",
    "# Fill the groups array starting with 0. Each identifier combo (participant session) will have one group number, and each individual choice in that session will have that group number.\n",
    "for identifier in Identifiers:\n",
    "    if identifier not in alreadycoded:\n",
    "        groups[Identifiers==identifier] = indextocount\n",
    "        indextocount = indextocount + 1\n",
    "        alreadycoded.append(identifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Simpler Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_simple = Choices\n",
    "\n",
    "# Future directions: might consider a transformation of amounts and delays like the following:\n",
    "#SSA_adj = (SSA - np.mean(SSA))/100\n",
    "#SSD_adj = (SSD - np.mean(SSD))/100\n",
    "#LLA_adj = (LLA - np.mean(LLA))/100\n",
    "#LLD_adj = (LLD - np.mean(LLD))/100\n",
    "\n",
    "\n",
    "with pm.Model() as model_fancy:\n",
    "\n",
    "    # Hyperparameters for k\n",
    "    mu_k = pm.Beta('mu_k',mu=0.01,sd=0.05)\n",
    "    sd_k = pm.Beta('sd_k',mu=0.05,sd=0.05)\n",
    "\n",
    "    k = pm.Beta('k',mu=mu_k,sd=sd_k, shape=np.size(np.unique(groups))) #mu=0.1, mu=0.07,sd=0.1 05\n",
    "    b = pm.HalfNormal('b',sd=0.01, shape=np.size(np.unique(groups))) #mu=0.1, mu=0.005,sd=0.01 mu=0,      # the more complex model does hyperparameters here too\n",
    "\n",
    "    # Lots of information about this in the explanation document\n",
    "    # Deterministic, by the way, indicates that we're not doing a distribution really. We're just doing a calculation.\n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(b[groups]*(SSAmount/(1+(k[groups]*SSDelay))-LLAmount/(1+(k[groups]*LLDelay))))))\n",
    "\n",
    "    # Could do observed=Choices here - it would be the same.\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=y_simple)\n",
    "\n",
    "    # Could increase target_accept if this doesn't run well (shouldn't be necessary). Reduce steps if you want it to go fast but be less good (ok for testing; note though that it'll still be hours probably)\n",
    "    trace_fancy = pm.sample(10000, tune=10000, target_accept=0.99) #,target_accept=0.9995  *********COMMENT/UNCOMMENT TO RUN/NOT RUN*********\n",
    "\n",
    "# Call the trace whatever you like. This just saves it. You don't want to run a whole model and then accidentally x-out your window or refresh or something and lose it all!\n",
    "pm.save_trace(trace_fancy, 'Trace from data generated by tiling smaller range.trace')\n",
    "# This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "Summary= az.summary(trace_fancy,round_to=10)\n",
    "# Again, call it what you want (yeah - call it what you want tooooo)\n",
    "Summary.to_csv(\"Summary from data generated by tiling smaller range.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Double Hierarchical Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benlg\\anaconda3\\lib\\site-packages\\deprecat\\classic.py:215: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  return wrapped_(*args_, **kwargs_)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [logb, k, sd_b, mu_b, sd_k, mu_k]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='80000' class='' max='80000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [80000/80000 7:11:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 10_000 tune and 10_000 draw iterations (40_000 + 40_000 draws total) took 25893 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "c:\\Users\\benlg\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_simple = Choices\n",
    "\n",
    "# By the way, the names here are all arbitrary. \"model_diff_dists_log,\" \"mu_k,\" \"logb\" - these are all made up and aren't meaningful code-wise\n",
    "with pm.Model() as model_diff_dists_log:\n",
    "\n",
    "    mu_k = pm.Beta('mu_k',mu=0.01,sd=0.05)\n",
    "    sd_k = pm.Beta('sd_k',mu=0.05,sd=0.05)\n",
    "\n",
    "    # Hyperparameters for the truncated normal distribution. \n",
    "    mu_b = pm.Normal('mu_b',mu=4.577, sd=1)\n",
    "    sd_b = pm.Exponential('sd_b',10)\n",
    "\n",
    "    k = pm.Beta('k',mu=mu_k,sd=sd_k, shape=np.size(np.unique(groups)))\n",
    "\n",
    "    logb = pm.TruncatedNormal('logb',mu=mu_b,sd=sd_b, lower=(-math.log(8.4)), upper=(-math.log(10**-8)),shape=np.size(np.unique(groups)))\n",
    "\n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp((math.e**-logb[groups])*(SSAmount/(1+(k[groups]*SSDelay))-LLAmount/(1+(k[groups]*LLDelay))))))\n",
    "\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=y_simple)\n",
    "\n",
    "    trace_diff_dists_log_full = pm.sample(10000, tune=10000, target_accept=0.99) #,target_accept=0.9995  *********UNCOMMENT TO RUN*********\n",
    "\n",
    "pm.save_trace(trace_diff_dists_log_full, 'Trace 7_27 dists norm full real data.trace')\n",
    "Summary_norm= az.summary(trace_diff_dists_log_full,round_to=10)\n",
    "Summary_norm.to_csv(\"Summary 7_27 real data norm beta dist.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Summary Table and Save Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is duplicated above. Unnecessary to run it again. I originally had them separate.\n",
    "\n",
    "pm.save_trace(trace_fancy, 'Trace from data generated by tiling.trace')\n",
    "Summary= az.summary(trace_fancy,round_to=10)\n",
    "Summary.to_csv(\"Summary from data generated by tiling.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Trace and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names to the trace that you want to load. You might want to do this early on if you're using the models that I already ran. I'll include a folder of traces.\n",
    "with model_fancy:\n",
    "    trace_fancy = pm.load_trace('Fancytrace2.trace')\n",
    "Summary= az.summary(trace_fancy,round_to=10)\n",
    "\n",
    "# \"Fancytrace3.trace\" is the best simple run. \"Trace 7_27 dists norm full real data.trace\" is the most recent double hierarchical run."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below accuracy comparison array code refers to \"Summary\". If you're using a different model, replace with whatever you've called the summary of that model.\n",
    "Summary = Summary_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates an accuracy comparison array between the MLE and BHM approaches. \n",
    "\n",
    "outarray = np.array([\"ID\",\"Day\",\"oldK\",\"newK\",\"oldB\",\"newB\",\"oldAcc\",\"newAcc\", \"oldBIC\", \"newBIC\", \"oldr2\", \"newr2\",\"kdiff\"])\n",
    "for pick in range(np.size(np.unique(Identifiers))):\n",
    "    boolpick = Identifiers==(np.unique(Identifiers)[pick])\n",
    "\n",
    "    SSA = SSAmount[boolpick]\n",
    "    SSD = SSDelay[boolpick]\n",
    "    LLA = LLAmount[boolpick]\n",
    "    LLD = LLDelay[boolpick]\n",
    "    Cs = Choices[boolpick]\n",
    "\n",
    "    oldK = Kappas[boolpick][1]\n",
    "    oldB = Betas[boolpick][1]\n",
    "    newK = Summary['mean'][4+pick]  # 4 when using the complex model; 2 otherwise    <IMPORTANT: Otherwise this will be wrong. Run tests to make sure that you're indexing the right values. Example: print(Summary_norm['mean'][120:])\n",
    "    \n",
    "    #Can just call this \"newB\" if you're using the simpler BHM.\n",
    "    newLogB = Summary['mean'][4+pick+116]\n",
    "\n",
    "    # Only use this with the new logb model. Otherwise it'll be totally wrong.\n",
    "    newB = math.e**(-newLogB)\n",
    "\n",
    "    kdiff = newK-oldK\n",
    "\n",
    "    # Little bit of array shenanigans to find accuracy. Choices count as accurate when the LL SV is greater than SS SV and Choice = 1, or when LLSV<LSSSV & C=0. Count and divide by total, *100, gets percent.\n",
    "    newKacc= 100*(np.sum(((LLA/(1+(newK*LLD)) > SSA/(1+(newK*SSD))) == Cs))/np.size(Cs))\n",
    "    oldKacc= 100*(np.sum(((LLA/(1+(oldK*LLD)) > SSA/(1+(oldK*SSD))) == Cs))/np.size(Cs))\n",
    "\n",
    "    # This analysis function is copied from the MLE code. See below. I made some prettiness changes in the MLE code that I haven't made here, but it runs the same.\n",
    "    oldLL,oldLL0,oldAIC,oldBIC,oldr2,oldcorrect = analysis(Cs,SSA,SSD,LLA,LLD,1,oldK,oldB)\n",
    "    newLL,newLL0,newAIC,newBIC,newr2,newcorrect = analysis(Cs,SSA,SSD,LLA,LLD,1,newK,newB)\n",
    "\n",
    "    row = np.array((IDs[boolpick][1], Days[boolpick][1], oldK, newK, oldB, newB, oldKacc, newKacc, oldBIC, newBIC, oldr2, newr2, kdiff))\n",
    "    \n",
    "    outarray = np.vstack((outarray,row))\n",
    "\n",
    "\n",
    "print(outarray[1:,1:])\n",
    "\n",
    "# Make a row of averages and slap it on top of the existing array of values.\n",
    "avesrow = np.average((outarray[1:,1:]).astype(float),0) #np.reshape( ,(1,))\n",
    "outarray = np.vstack((outarray[0],np.hstack((np.array([\"Averages\"]),avesrow)),outarray[1:]))\n",
    "\n",
    "pd.DataFrame(outarray).to_csv('Accuracy Comparison Array with Double Hierarchical Model.csv', header=False, index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions from Non-Bayesian Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: All of this is pretty much copied from the MLE code.\n",
    "\n",
    "# naming conventions that I've kept for consistency with the original code - \"v1\" refers to SSAmount, and \"v2\" refers to LLAmount.\n",
    "\n",
    "\n",
    "def analysis(choices,v1,d1,v2,d2,risk,given_k,beta):\n",
    "    # Changed from other program: added LLfromGiven functionality right here\n",
    "    given_beta = [beta,given_k]  #FYI: name conventions are wonky here. The pairing of b,k is referred to as \"beta\". We also call that stochasticity factor \"beta\". I think the latter is not quite proper, but I don't know.\n",
    "    negLL = local_negLL(given_beta,choices,v1,d1,v2,d2,risk)\n",
    "    \n",
    "    # Unrestricted log-likelihood\n",
    "    LL = -negLL\n",
    "\n",
    "    # Restricted log-likelihood\n",
    "    LL0 = np.sum((choices==1)*math.log(0.5) + (1-(choices==1))*math.log(0.5))\n",
    "\n",
    "    # Akaike Information Criterion\n",
    "    AIC = -2*LL + 2*2  #CHANGE TO len(results.x) IF USING A DIFFERENT MODEL (parameters != 2)\n",
    "\n",
    "    # Bayesian information criterion\n",
    "    BIC = -2*LL + 2*math.log(len(v1))  #len(results.x)\n",
    "\n",
    "    #R squared\n",
    "    r2 = 1 - LL/LL0\n",
    "\n",
    "    #Percent accuracy\n",
    "    k_for_accuracy = given_k\n",
    "    beta_for_accuracy = [beta,k_for_accuracy]\n",
    "    parray = np.array(choice_prob(v1,d1,v2,d2,beta_for_accuracy,risk))\n",
    "    correct =sum((parray>=0.5)==choices)/len(v1)\n",
    "\n",
    "    #print(\"k=\",given_k)\n",
    "    #print(\"LL\",LL,\"AIC\",AIC,\"BIC\",BIC,\"R2\",r2,\"correct\",correct)\n",
    "    return(LL,LL0,AIC,BIC,r2,correct)\n",
    "\n",
    "def LLfromGiven(given_k, given_b, choices, v1, d1, v2, d2, risk):   #not currently in use\n",
    "    given_beta = [given_b,given_k]\n",
    "    negLL = local_negLL(given_beta,choices,v1,d1,v2,d2,risk)\n",
    "    return negLL\n",
    "\n",
    "def local_negLL(beta,choices_list,v1,d1,v2,d2,risk):\n",
    "\n",
    "    ps = np.array(choice_prob(v1,d1,v2,d2,beta,risk))\n",
    "    choices = np.array(choices_list)\n",
    "\n",
    "    # Trap log(0)\n",
    "    ps[ps==0] = 0.0001\n",
    "    ps[ps==1] = 0.9999\n",
    "    \n",
    "    # Log-likelihood\n",
    "\n",
    "    err = (choices==1)*np.log(ps) + ((choices==0))*np.log(1-ps)\n",
    "    # Sum of -log-likelihood\n",
    "    sumerr = -sum(err)\n",
    "    return sumerr\n",
    "\n",
    "def choice_prob(v1,d1,v2,d2,beta,risk):\n",
    "    ps = []\n",
    "\n",
    "    for n in range(len(v1)):\n",
    "        #print(v1[n])\n",
    "        SV_1 = discount(v1[n],d1[n],beta[1],risk)\n",
    "        SV_2 = discount(v2[n],d2[n],beta[1],risk)\n",
    "        try: \n",
    "            p = 1 / (1 + math.exp(beta[0]*(SV_1-SV_2)))\n",
    "        except OverflowError:\n",
    "            #print(\"beta:\",beta[0],\"k:\",beta[1],\"SV_1:\",SV_1,\"SV_2\",SV_2,\"imm val\",v1[n],\"imm delay\",d1[n], \"del val\",v2[n],\"del del\",d2[n])\n",
    "            p = 0\n",
    "            #raise SystemExit(0)\n",
    "            #break\n",
    "        ps.append(p)\n",
    "        \n",
    "    return ps\n",
    "\n",
    "def discount(v,d,kappa,risk):\n",
    "    SV = (v**risk)/(1+kappa*d)\n",
    "    return SV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fully Pooled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a fully pooled model. This is not good for our case. It will just get one k and one b for the whole population.\n",
    "\n",
    "with pm.Model() as pooled_model:\n",
    "    slope = pm.Beta('slope', 1, 5)\n",
    "    noise = pm.Exponential('noise', 10)\n",
    "    \n",
    "    obs = pm.Normal('obs', ((LLA/(1+(slope/1000)*LLD))>=SSA/(1+(slope/1000)*SSD)), noise, observed=Cs)\n",
    "    \n",
    "    pooled_trace = pm.sample(return_inferencedata=True)\n",
    "\n",
    "pm.summary(pooled_trace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Super Simple Non-Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple model. This is not good for our case. It will just get one k and one b for each session, but it won't incorporate everyone's data. Returns wonky values as far as I remember.\n",
    "\n",
    "with pm.Model() as model_simple:\n",
    "\n",
    "    k = pm.Beta('k',mu=0.01,sd=0.05) #mu=0.1, mu=0.07,sd=0.1 05\n",
    "    b = pm.HalfNormal('b',sd=0.01) #mu=0.1, mu=0.005,sd=0.01 mu=0,\n",
    "\n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(b*(SSA/(1+(k*SSD))-LLA/(1+(k*LLD))))))\n",
    "\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=y_simple)\n",
    "\n",
    "    trace_simple = pm.sample(10000, tune=10000, target_accept=0.99)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Distributions That Worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the distribution for beta that we replicate in the PyMC3 code above. It results in a nice shape (see description file)\n",
    "\n",
    "#normal_for_log = np.random.normal(4.577,10, 1000000)\n",
    "#e_log_normal = np.exp(-normal_for_log[((normal_for_log>(-math.log(8.4)))*(normal_for_log<(-math.log(10**-8))))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Everything below is assorted nonsense. Proceed at your own risk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoarding Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#if(IDs[boolpick][1]==\"8475\" and Days[boolpick][1] == \"3\"):\n",
    "        #print(SSA[:6])\n",
    "        #print(Cs[:6])\n",
    "        #disparraytitles = np.array([\"SSA\",\"LLA\",\"SSD\",\"LLD\",\"SVImm\",\"SVDel\",\"Real Choice\",\"Pred. Choice\"])\n",
    "        #disparraynums = np.hstack((np.reshape(SSA[:8],(8,1)), np.reshape(LLA[:8],(8,1)), np.reshape(SSD[:8],(8,1)), np.reshape(LLD[:8],(8,1)), np.reshape(np.round((SSA/(1+(newK*SSD))))[:8],(8,1)), np.reshape(np.round((LLA/(1+(newK*LLD))))[:8],(8,1)), np.reshape(Cs[:8],(8,1)), np.reshape((LLA/(1+(newK*LLD)) > SSA/(1+(newK*SSD)))[:8],(8,1))))\n",
    "        #print(np.shape(disparraynums))\n",
    "        #disparray = (np.vstack((disparraytitles,disparraynums)))\n",
    "        #print(disparray)\n",
    "\n",
    "\n",
    "\n",
    "#SSA = SSAmount[boolpick*boolselector]\n",
    " #   SSD = SSDelay[boolpick*boolselector]\n",
    "  #  LLA = LLAmount[boolpick*boolselector]\n",
    "   # LLD = LLDelay[boolpick*boolselector]\n",
    "    #Cs = Choices[boolpick*boolselector]\n",
    "  #  Bs = Betas[boolpick*boolselector]\n",
    "  #  Ks = Kappas[boolpick*boolselector]\n",
    "\n",
    "    \n",
    "\n",
    "    #try:\n",
    "        #row = np.array((IDs[boolpick][1], Days[boolpick][1], do_one_Bay(SSA,SSD,LLA,LLD,Cs,Ks)))\n",
    "    #except:\n",
    "    #    pick = pick-1\n",
    "    #    print(\"ack\")\n",
    "\n",
    "#    oldK = 0.0709568085277114\n",
    "#newK = 0.073\n",
    "#print(\"newK accuracy: \", 100*(np.sum(((LLA/(1+(newK*LLD)) > SSA/(1+(newK*SSD))) == Cs))/np.size(Cs)))\n",
    "#print(\"oldK accuracy: \", 100*(np.sum(((LLA/(1+(oldK*LLD)) > SSA/(1+(oldK*SSD))) == Cs))/np.size(Cs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Prior Distributions - LogNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal here was to use a LogNormal distribution for log b. They both say \"log\" in the name, but I think this was not a good idea.\n",
    "\n",
    "testbool = ((groups>=6)*(groups<=9))\n",
    "test_groups = groups[testbool]-(groups[testbool][0])\n",
    "test_SSAmount = SSAmount[testbool]\n",
    "test_SSDelay = SSDelay[testbool]\n",
    "test_LLAmount = LLAmount[testbool]\n",
    "test_LLDelay = LLDelay[testbool]\n",
    "test_Choices = Choices[testbool]\n",
    "\n",
    "#def do_one_Bay(SSA,SSD,LLA,LLD,Cs,Ks):\n",
    "y_simple = test_Choices\n",
    "#SSA_adj = (SSA - np.mean(SSA))/100\n",
    "#SSD_adj = (SSD - np.mean(SSD))/100\n",
    "#LLA_adj = (LLA - np.mean(LLA))/100\n",
    "#LLD_adj = (LLD - np.mean(LLD))/100\n",
    "\n",
    "b_min = 10**-3\n",
    "b_max = 10\n",
    "\n",
    "\n",
    "with pm.Model() as model_diff_dists:\n",
    "\n",
    "    mu_k = pm.Beta('mu_k',mu=0.01,sd=0.05)\n",
    "    sd_k = pm.Beta('sd_k',mu=0.05,sd=0.05)\n",
    "\n",
    "    mu_b = pm.Normal('mu_b', mu=4.577, sd=1)\n",
    "    sd_b = pm.Exponential('sd_b',1)\n",
    "\n",
    "    k = pm.Beta('k',mu=mu_k,sd=sd_k, shape=np.size(np.unique(test_groups))) #mu=0.1, mu=0.07,sd=0.1 05\n",
    "    #b = tt.exp(pm.Uniform('b',lower=math.log(b_min),upper=math.log(b_max), shape=np.size(np.unique(test_groups)))) #mu=0.1, mu=0.005,sd=0.01 mu=0,      #do hyperpriors here too\n",
    "    logb = pm.LogNormal('logb',mu=4.577,sd=0.7, shape=np.size(np.unique(test_groups)))\n",
    "\n",
    "    #uniform dist. over log(beta)\n",
    "\n",
    "    #SV_Imm = pm.Deterministic('SV_Imm', SSA/(1+(k*SSD))) #_adj\n",
    "    #SV_Del = pm.Deterministic('SV_Del', LLA/(1+(k*LLD)))\n",
    "    #prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(b*(SV_Imm-SV_Del))))\n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp((math.e**-logb[test_groups])*(test_SSAmount/(1+(k[test_groups]*test_SSDelay))-test_LLAmount/(1+(k[test_groups]*test_LLDelay))))))\n",
    "\n",
    "    #mu = a + pm.math.dot(x_c,b)\n",
    "    #theta = pm.Deterministic('theta',pm.math.sigmoid(mu))\n",
    "    #bd = pm.Deterministic('bd', -k/b)\n",
    "\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=y_simple)\n",
    "\n",
    "    trace_diff_dists = pm.sample(1000, tune=10000, target_accept=0.99) #,target_accept=0.9995  *********UNCOMMENT TO RUN*********\n",
    "\n",
    "#newK = az.summary(trace_simple)[\"mean\"][0]\n",
    "#oldK = Ks[0]\n",
    "#oldAcc = 100*(np.sum(((LLA/(1+(oldK*LLD)) > SSA/(1+(oldK*SSD))) == Cs))/np.size(Cs))  \n",
    "#newAcc = 100*(np.sum(((LLA/(1+(newK*LLD)) > SSA/(1+(newK*SSD))) == Cs))/np.size(Cs))\n",
    "\n",
    "    #return newK,oldAcc,newAcc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing but just for one group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does the above but just on one group. A tester for speed.\n",
    "\n",
    "group_num = 9\n",
    "testbool = (groups==group_num)\n",
    "test_groups = groups[testbool]-(groups[testbool][0])\n",
    "test_SSAmount = SSAmount[testbool]\n",
    "test_SSDelay = SSDelay[testbool]\n",
    "test_LLAmount = LLAmount[testbool]\n",
    "test_LLDelay = LLDelay[testbool]\n",
    "test_Choices = Choices[testbool]\n",
    "\n",
    "#def do_one_Bay(SSA,SSD,LLA,LLD,Cs,Ks):\n",
    "y_simple = test_Choices\n",
    "#SSA_adj = (SSA - np.mean(SSA))/100\n",
    "#SSD_adj = (SSD - np.mean(SSD))/100\n",
    "#LLA_adj = (LLA - np.mean(LLA))/100\n",
    "#LLD_adj = (LLD - np.mean(LLD))/100\n",
    "\n",
    "b_min = 10**-3\n",
    "b_max = 10\n",
    "\n",
    "\n",
    "with pm.Model() as model_diff_dists_e:\n",
    "\n",
    "    #mu_k = pm.Beta('mu_k',mu=0.01,sd=0.05)\n",
    "    #sd_k = pm.Beta('sd_k',mu=0.05,sd=0.05)\n",
    "\n",
    "    k = pm.Beta('k',mu=0.01,sd=0.05) #mu=0.1, mu=0.07,sd=0.1 05 , shape=np.size(np.unique(test_groups))\n",
    "    logb = pm.LogNormal('logb',mu=4.577,sd=0.7) #mu=0.1, mu=0.005,sd=0.01 mu=0,      #do hyperpriors here too #, shape=np.size(np.unique(test_groups) #Log\n",
    "        #logb = pm.Normal('logb',mu=-4.577,sd=0.7) #mu=0.1, mu=0.005,sd=0.01 mu=0,      #do hyperpriors here too #, shape=np.size(np.unique(test_groups) #Log\n",
    "\n",
    "    #b = pm.Deterministic('b',math.e**logb)\n",
    "\n",
    "    #uniform dist. over log(beta)\n",
    "\n",
    "    #SV_Imm = pm.Deterministic('SV_Imm', SSA/(1+(k*SSD))) #_adj\n",
    "    #SV_Del = pm.Deterministic('SV_Del', LLA/(1+(k*LLD)))\n",
    "    #prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(b*(SV_Imm-SV_Del))))\n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp((math.e**(-logb))*(test_SSAmount/(1+(k*test_SSDelay))-test_LLAmount/(1+(k*test_LLDelay)))))) # [test_groups]\n",
    "\n",
    "    #mu = a + pm.math.dot(x_c,b)\n",
    "    #theta = pm.Deterministic('theta',pm.math.sigmoid(mu))\n",
    "    #bd = pm.Deterministic('bd', -k/b)\n",
    "\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=y_simple)\n",
    "\n",
    "    trace_diff_dists_e = pm.sample(1000, tune=10000, target_accept=0.99) #,target_accept=0.9995  *********UNCOMMENT TO RUN*********\n",
    "\n",
    "#newK = az.summary(trace_simple)[\"mean\"][0]\n",
    "#oldK = Ks[0]\n",
    "#oldAcc = 100*(np.sum(((LLA/(1+(oldK*LLD)) > SSA/(1+(oldK*SSD))) == Cs))/np.size(Cs))  \n",
    "#newAcc = 100*(np.sum(((LLA/(1+(newK*LLD)) > SSA/(1+(newK*SSD))) == Cs))/np.size(Cs))\n",
    "\n",
    "    #return newK,oldAcc,newAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm.save_trace(trace_diff_dists, 'Trace from data generated by tiling smaller range with .trace')\n",
    "Summary_lognorm= az.summary(trace_diff_dists,round_to=10)\n",
    "Summary_lognorm.to_csv(\"tests/Summary from data generated by tiling smaller range with log normal.csv\")\n",
    "#print(Summary[\"mean\"][0])\n",
    "#Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d5eda77765311109b2c027e144dcf58f89dd96008cdf29c2e6b03e99df71a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian parameter estimation \n",
    "\n",
    "Written for CPDM task as part of the IDM dataset collected online with Mturk. Here we are using the CASANDRE model (instead of utility model) to analyze the CPDM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in/Generic Imports\n",
    "import os,sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 99\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the name of the directory\n",
    "# where the this file is present.\n",
    "# current = os.path.dirname(os.path.realpath(__file__))\n",
    "current = os.path.dirname(os.getcwd())\n",
    " \n",
    "# Getting the parent directory name\n",
    "# where the current directory is present.\n",
    "# parent = os.path.dirname(os.path.dirname(current))\n",
    "# parent = current\n",
    "parent = '/Users/pizarror/IDM'\n",
    "# print(parent)\n",
    "#/Users/pizarror/IDM\n",
    "\n",
    "# adding the parent directory to\n",
    "# the sys.path.\n",
    "sys.path.append(parent)\n",
    "\n",
    "from IDM_model.src import model_functions as mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load_data(subject='23_IDM_0144',fn='/tmp',cols=[]):\n",
    "    cpdm_df = pd.read_csv(fn)\n",
    "    task='cpdm'\n",
    "    cpdm_df = mf.remap_response(cpdm_df,task=task)\n",
    "    cpdm_df = mf.drop_pract(cpdm_df,task=task)\n",
    "    cpdm_df,response_rate = mf.drop_non_responses(cpdm_df,task=task,verbose=False)\n",
    "    data = mf.get_data(cpdm_df,cols,alpha_hat=1)[0]\n",
    "    data['subject'] = subject\n",
    "    return data\n",
    "\n",
    "def diganostic_plots(trace,experiment='experiment',utility_dir='/tmp/',subject='23_IDM_0001',task='cdd_nlh',coords={},var_names=['kappa','gamma'],figsize=(10,10)):\n",
    "\n",
    "    bh_dir = os.path.join(utility_dir,subject,task,'bh')\n",
    "    if not os.path.exists(bh_dir):\n",
    "        os.makedirs(bh_dir)\n",
    "    print('Saving diagnostic plots to bh_dir : {}'.format(bh_dir))\n",
    "\n",
    "    title_dict = {'fontsize':15}\n",
    "\n",
    "    # 2by2 : rows 2 varialbes, cols 2 for distribution and sampled values\n",
    "    axes = az.plot_trace(trace, var_names=var_names,coords=coords,compact=False)\n",
    "    for r in range(axes.shape[0]):\n",
    "        for c in range(axes.shape[1]):\n",
    "            axes[r,c].set_title('{}: {}'.format(subject,var_names[r]))\n",
    "    plt.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_trace_plot.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "    \n",
    "    axes = az.plot_pair(trace,kind='kde', coords=coords,var_names=var_names,marginals=True)\n",
    "    axes[0,0].set_title(subject,fontdict=title_dict)\n",
    "    axes[1,0].set_ylabel(var_names[1])\n",
    "    axes[1,0].set_xlabel(var_names[0])\n",
    "    plt.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_bivariate_densities.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "    \n",
    "    axes = az.plot_posterior(trace,var_names=var_names,coords=coords)\n",
    "    # print(axes.shape)\n",
    "    for c in range(axes.shape[0]):\n",
    "        axes[c].set_title('{}: {}'.format(subject,var_names[c]),fontdict=title_dict)\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_posterior.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(var_names), figsize=figsize)\n",
    "    az.plot_rank(trace,var_names=var_names,coords=coords,ax=axes)\n",
    "    for c in range(axes.shape[0]):\n",
    "        axes[c].set_title('{}: {}'.format(subject,var_names[c]),fontdict=title_dict)\n",
    "    fig.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_rank_plot_bars.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(var_names), figsize=figsize)\n",
    "    axes = az.plot_rank(trace,var_names=var_names, coords=coords,kind=\"vlines\",vlines_kwargs={'lw':0}, marker_vlines_kwargs={'lw':3},ax=axes)\n",
    "    for c in range(axes.shape[0]):\n",
    "        axes[c].set_title('{}: {}'.format(subject,var_names[c]),fontdict=title_dict)\n",
    "    fig.tight_layout()\n",
    "    fig_fn = os.path.join(bh_dir,'{}_{}_rank_plot_lines.{}.eps'.format(subject,task,experiment))\n",
    "    plt.savefig(fig_fn,format='eps')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hierarchical Model (BHM)\n",
    "\n",
    "We pooled all data together and ran simple BH model in complete_pool_as_prior.\n",
    "\n",
    "We are using complete pooling to generate priors for when we implement a higherarchical bayesian model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We will load the data from all participants so we can run the modeling schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 10 seconds\n",
    "\n",
    "# we will change this when we change utility to 1st level analysis (or split)\n",
    "split_dir = '/Volumes/UCDN/datasets/IDM/split/'\n",
    "utility_dir = '/Volumes/UCDN/datasets/IDM/utility/'\n",
    "save_dir = '/Volumes/UCDN/datasets/IDM/utility/BHM/cpdm/'\n",
    "subjs = sorted(glob.glob(os.path.join(split_dir,'23_IDM_*')))\n",
    "task = 'cpdm'\n",
    "cols = ['cpdm_choice','cpdm_gabor_orient', 'cpdm_gabor_contrast', 'cpdm_run_dimension', 'cpdm_trial_resp.keys','cpdm_trial_resp.rt']\n",
    "data = pd.DataFrame(columns=['subject']+cols)\n",
    "\n",
    "for subj_id,s in enumerate(subjs):\n",
    "    subject = os.path.basename(s)\n",
    "    fn  = os.path.join(s,task,'{}_{}.csv'.format(os.path.basename(s),task))\n",
    "    if os.path.exists(fn):\n",
    "        subj_data = read_load_data(subject=subject,fn=fn,cols=cols)\n",
    "        # for c in cols:\n",
    "            # subj_data[c] = subj_data[c].astype(float)        \n",
    "        subj_data['subject_id'] = int(subj_id)\n",
    "        data = pd.concat([data,subj_data],ignore_index=True)\n",
    "\n",
    "data.head(998)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = data['subject'].unique()\n",
    "# subjects = subjects[:10]\n",
    "# print(subjects)\n",
    "data = data.loc[data['subject'].isin(subjects)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = data['subject'].unique()\n",
    "nb_subj = subjects.shape[0]\n",
    "nb_trials = data.shape[0]//nb_subj\n",
    "subj_id_list = data['subject_id'].to_list()\n",
    "subj_id = [int(s) for s in subj_id_list]\n",
    "# subj_id = data['subject'].to_list()\n",
    "old_id = np.array([ [s]*nb_trials for s in range(nb_subj) ]).flatten()\n",
    "\n",
    "\n",
    "\n",
    "delay_amt = data['cdd_delay_amt'].values\n",
    "delay_wait = data['cdd_delay_wait'].values\n",
    "immed_amt = data['cdd_immed_amt'].values\n",
    "immed_wait = data['cdd_immed_wait'].values\n",
    "alpha = data['alpha'].values\n",
    "choices = data['cdd_choice'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# parameters to model\n",
    "# nParams = 2 + numTasks + totRel + numTasks*nConfCrit; % [Guess rate, stimulus criterion], [meta-uncertainty], [stimulus sensitivity], [confidence criteria]\n",
    "\n",
    "\n",
    "# Required order for getLlhChoice: [guess rate, stim sens, stim crit, meta-uncertainty, conf criteria]\n",
    "\n",
    "\n",
    "# 2 :: [Guess rate, stimulus criterion]\n",
    "# numTasks :: [meta-uncertainty]\n",
    "# totRel :: [stimulus sensitivity]\n",
    "# numTasks*nConfCrit :: [confidence criteria]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Hierarchical Model\n",
    "\n",
    "Developed under parameter receovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tStep1 = time.time()\n",
    "\n",
    "# We will fit a model for each subject\n",
    "with pm.Model() as model_simple:\n",
    "\n",
    "    # Hyperparameters for kappa and gamma\n",
    "    # estimated from MLE approximations : np.exp(-3.60) = 0.0273, np.sqrt(1.71)=1.308\n",
    "    mu_kappa_hyper = pm.Beta('mu_kappa_hyper',mu=np.exp(-3.60),sigma=0.01)\n",
    "    sd_kappa_hyper = pm.Normal('sd_kappa_hyper',mu=np.sqrt(1.71),sigma=0.1)\n",
    "    # estimated from MLE approximations : np.sqrt(2.30) = 1.517\n",
    "    sd_gamma_hyper = pm.Normal('sd_hyper',mu=np.sqrt(2.30),sigma=0.1)\n",
    "\n",
    "    kappa = pm.LogNormal('kappa',mu=mu_kappa_hyper,sigma=sd_kappa_hyper,shape=np.size(np.unique(subj_id)))\n",
    "    gamma = pm.HalfNormal('gamma',sigma=sd_gamma_hyper,shape=np.size(np.unique(subj_id)))\n",
    "    \n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( (delay_amt**alpha[subj_id])/(1+(kappa[subj_id]*delay_wait)) \n",
    "                                                                            - (immed_amt**alpha[subj_id])/(1+(kappa[subj_id]*immed_wait)) ))))\n",
    "\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "    trace_prior = pm.sample(10000, tune=1000, cores=5,target_accept=0.99,progressbar=False)\n",
    "\n",
    "\n",
    "\n",
    "# This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "summary= az.summary(trace_prior,round_to=10)\n",
    "fn = os.path.join(save_dir,'BHM_model_summary_v004.csv')\n",
    "print('Saving to : {}'.format(fn))\n",
    "summary.to_csv(fn)\n",
    "\n",
    "fn = os.path.join(save_dir,'BHM_model_trace_v004.pkl')\n",
    "print('Saving to : {}'.format(fn))\n",
    "with open(fn,'wb') as buff:\n",
    "    pickle.dump({'trace':trace_prior},buff)\n",
    "    # pm.save_trace(trace_prior,fn)\n",
    "\n",
    "print('Time to complete {} aggregate BHM : {} minutes'.format(len(subjects),(time.time() - tStep1)/60.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract parameter estimates and save\n",
    "\n",
    "We can incorporate this into the script above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean(fn,var_names=['kappa','gamma'],subjects=[]):\n",
    "    nb_subjects = len(subjects)\n",
    "    df = pd.read_csv(fn,index_col=0)\n",
    "    df_bhm = pd.DataFrame([],columns=var_names)\n",
    "    df_bhm['subject'] = subjects\n",
    "    for var in var_names:\n",
    "        ind_list = ['{}[{}]'.format(var,sub_id) for sub_id in range(nb_subjects)]\n",
    "        df_bhm[var] = df.loc[df.index.isin(ind_list)]['mean'].reset_index(drop=True)\n",
    "    return df_bhm\n",
    "\n",
    "experiment='v004'\n",
    "bhm_dir = '/Volumes/UCDN/datasets/IDM/utility/BHM/'\n",
    "bhm_fn = os.path.join(bhm_dir,'cdd_nlh','BHM_model_summary_{}.csv'.format(experiment))\n",
    "df_bhm = extract_mean(bhm_fn,var_names=['kappa','gamma'],subjects=subjects)\n",
    "split_CDD_fn = os.path.join(bhm_dir,'split_CDD_nlh_BHM.csv')\n",
    "df_bhm.to_csv(split_CDD_fn)\n",
    "df_bhm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic plots\n",
    "\n",
    "Too many subjects to run `diagnistic_plots()`  but can run them individually\n",
    "Trace, posterior, rank plots\n",
    "\n",
    "... need to figure out for each subject how to plot_pair() which plots the bivariate distirbutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set(subj_id):\n",
    "    coords={'kappa_dim_0': [s],'gamma_dim_0':[s]}\n",
    "    diganostic_plots(trace_prior,experiment=experiment,utility_dir=utility_dir,subject=subjects[s],task='cdd_nlh',coords=coords,var_names=['kappa','gamma'],figsize=(10,10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d5eda77765311109b2c027e144dcf58f89dd96008cdf29c2e6b03e99df71a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

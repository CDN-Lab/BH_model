{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd \n",
    "import glob\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the name of the directory\n",
    "# where the this file is present.\n",
    "# current = os.path.dirname(os.path.realpath(__file__))\n",
    "current = os.path.dirname(os.getcwd())\n",
    " \n",
    "# Getting the parent directory name\n",
    "# where the current directory is present.\n",
    "# parent = os.path.dirname(os.path.dirname(current))\n",
    "parent = current\n",
    "# print(parent)\n",
    "#/Users/pizarror/IDM\n",
    "\n",
    "# adding the parent directory to\n",
    "# the sys.path.\n",
    "sys.path.append(parent)\n",
    "\n",
    "from IDM_model.src import model_functions as mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load_data(subject='23_IDM_0144',fn='/tmp',alpha0=1.0,cols=[]):\n",
    "    cdd_df = pd.read_csv(fn)\n",
    "    task='cdd'\n",
    "    cdd_df = mf.drop_pract(cdd_df,task=task)\n",
    "    cdd_df,response_rate = mf.drop_non_responses(cdd_df,task=task,verbose=False) \n",
    "    data = mf.get_data(cdd_df,cols,alpha_hat=alpha0)[0]\n",
    "    data['subject'] = subject\n",
    "    return data \n",
    "\n",
    "def diganostic_plots(trace,coords={},var_names=['kappa','gamma'],figsize=(10,10)):\n",
    "    # increase number of subplots\n",
    "    # az.rcParams[\"plot.max_subplots\"] = nb_subjects*len(var_names)\n",
    "    \n",
    "    az.plot_trace(trace, var_names=var_names,coords=coords,compact=False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # az.plot_pair(trace,kind='kde', var_names=var_names,marginals=True)\n",
    "    az.plot_posterior(trace,var_names=var_names,coords=coords)\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(var_names), figsize=figsize)\n",
    "    az.plot_rank(trace,var_names=var_names,coords=coords,ax=axes)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(var_names), figsize=figsize)\n",
    "    axes = az.plot_rank(trace,var_names=var_names, coords=coords,kind=\"vlines\",vlines_kwargs={'lw':0}, marker_vlines_kwargs={'lw':3},ax=axes)\n",
    "    # plt.ylim([-0.001,0.001])\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hierarchical Model (BHM)\n",
    "\n",
    "We pooled all data together and ran simple BH model in complete_pool_as_prior.\n",
    "\n",
    "We are using complete pooling to generate priors for when we implement a higherarchical bayesian model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We will load the data from all participants so we can run the modeling schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>cdd_choice</th>\n",
       "      <th>cdd_immed_amt</th>\n",
       "      <th>cdd_delay_amt</th>\n",
       "      <th>cdd_immed_wait</th>\n",
       "      <th>cdd_delay_wait</th>\n",
       "      <th>alpha</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23_IDM_0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject  cdd_choice  cdd_immed_amt  cdd_delay_amt  cdd_immed_wait   \n",
       "0  23_IDM_0001         1.0            5.0           26.0             0.0  \\\n",
       "1  23_IDM_0001         1.0            2.0           22.0             0.0   \n",
       "2  23_IDM_0001         0.0            2.0            6.0             0.0   \n",
       "3  23_IDM_0001         0.0           15.0           15.0             0.0   \n",
       "4  23_IDM_0001         1.0           15.0           55.0             0.0   \n",
       "5  23_IDM_0001         1.0            2.0           65.0             0.0   \n",
       "6  23_IDM_0001         0.0           15.0           20.0             0.0   \n",
       "7  23_IDM_0001         1.0           15.0           26.0             0.0   \n",
       "8  23_IDM_0001         0.0            5.0           10.0             0.0   \n",
       "9  23_IDM_0001         0.0            5.0            4.0             0.0   \n",
       "\n",
       "   cdd_delay_wait  alpha  subject_id  \n",
       "0            29.0    1.0         0.0  \n",
       "1            90.0    1.0         0.0  \n",
       "2            90.0    1.0         0.0  \n",
       "3           151.0    1.0         0.0  \n",
       "4            90.0    1.0         0.0  \n",
       "5            29.0    1.0         0.0  \n",
       "6            59.0    1.0         0.0  \n",
       "7             6.0    1.0         0.0  \n",
       "8           149.0    1.0         0.0  \n",
       "9            31.0    1.0         0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes about 10 seconds\n",
    "\n",
    "# we will change this when we change utility to 1st level analysis (or split)\n",
    "split_dir = '/Volumes/UCDN/datasets/IDM/split/'\n",
    "save_dir = '/Volumes/UCDN/datasets/IDM/BH/csv'\n",
    "subjs = sorted(glob.glob(os.path.join(split_dir,'23_IDM_*')))\n",
    "task = 'cdd'\n",
    "cols = ['cdd_choice','cdd_immed_amt','cdd_delay_amt','cdd_immed_wait','cdd_delay_wait','alpha']\n",
    "data = pd.DataFrame(columns=['subject']+cols)\n",
    "\n",
    "for subj_id,s in enumerate(subjs):\n",
    "    subject = os.path.basename(s)\n",
    "    fn  = os.path.join(s,task,'{}_{}.csv'.format(os.path.basename(s),task))\n",
    "    if os.path.exists(fn):\n",
    "        subj_data = read_load_data(subject=subject,fn=fn,alpha0=1.0,cols=cols)\n",
    "        for c in cols:\n",
    "            subj_data[c] = subj_data[c].astype(float)        \n",
    "        subj_data['subject_id'] = int(subj_id)\n",
    "        data = pd.concat([data,subj_data],ignore_index=True)\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = data['subject'].unique()\n",
    "subjects = subjects[:10]\n",
    "# print(subjects)\n",
    "data = data.loc[data['subject'].isin(subjects)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = data['subject'].unique()\n",
    "nb_subj = subjects.shape[0]\n",
    "nb_trials = data.shape[0]//nb_subj\n",
    "subj_id_list = data['subject_id'].to_list()\n",
    "subj_id_nb = [int(s) for s in subj_id_list]\n",
    "\n",
    "subj_id_IDM = data['subject'].to_list()\n",
    "\n",
    "old_id = np.array([ [s]*nb_trials for s in range(nb_subj) ]).flatten()\n",
    "\n",
    "delay_amt = data['cdd_delay_amt'].values\n",
    "delay_wait = data['cdd_delay_wait'].values\n",
    "immed_amt = data['cdd_immed_amt'].values\n",
    "immed_wait = data['cdd_immed_wait'].values\n",
    "choices = data['cdd_choice'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['23_IDM_0001', '23_IDM_0002', '23_IDM_0003', '23_IDM_0004',\n",
       "       '23_IDM_0005', '23_IDM_0006', '23_IDM_0007', '23_IDM_0008',\n",
       "       '23_IDM_0009', '23_IDM_0010'], dtype='<U11')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(subj_id_IDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from completely_pooled_model\n",
    "\n",
    "We use the kappa and gamma from previous run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For kappa, use the following (mu,sigma) : (0.0202632834,0.0005014986)\n",
      "For gamma, use the following (mu,sigma) : (0.1300484166,0.0027491151)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fn = os.path.join(save_dir,'completely_pooled_model.csv')\n",
    "pool_model = pd.read_csv(fn,index_col=0)\n",
    "\n",
    "mu_kappa_hat,std_kappa_hat = pool_model.loc['kappa[0]','mean'],pool_model.loc['kappa[0]','sd']\n",
    "mu_gamma_hat,std_gamma_hat = pool_model.loc['gamma[0]','mean'],pool_model.loc['gamma[0]','sd']\n",
    "\n",
    "print('For kappa, use the following (mu,sigma) : ({},{})'.format(mu_kappa_hat, std_kappa_hat))\n",
    "print('For gamma, use the following (mu,sigma) : ({},{})'.format(mu_gamma_hat, std_gamma_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/data.py:427: UserWarning: The `mutable` kwarg was not specified. Before v4.1.0 it defaulted to `pm.Data(mutable=True)`, which is equivalent to using `pm.MutableData()`. In v4.1.0 the default changed to `pm.Data(mutable=False)`, equivalent to `pm.ConstantData`. Use `pm.ConstantData`/`pm.MutableData` or pass `pm.Data(..., mutable=False/True)` to avoid this warning.\n",
      "  warnings.warn(\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1\nApply node that caused the error: AdvancedSubtensor1(gamma_log___log, TensorConstant{[0 0 0 0 0..9 9 9 9 9]})\nToposort index: 4\nInputs types: [TensorType(float64, (1,)), TensorType(uint8, (950,))]\nInputs shapes: [(1,), (950,)]\nInputs strides: [(8,), (1,)]\nInputs values: [array([0.00773022]), 'not shown']\nOutputs clients: [[Elemwise{Composite}(AdvancedSubtensor1.0, TensorConstant{[ 29.  90... 11.  89.]}, TensorConstant{(1,) of 1.0}, TensorConstant{[26. 22.  ... 20. 35.]}, TensorConstant{[ 5.  2.  ... 15. 15.]}, TensorConstant{(1,) of -1.0}, AdvancedSubtensor1.0, TensorConstant{(1,) of 1}, TensorConstant{(1,) of 0}, y_1{[1 1 0 0 1..1 1 1 1 1]})]]\n\nBacktrace when the node is created (use PyTensor flag traceback__limit=N to make it longer):\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/ts/wpzrly5j2yxb42zf5v0w5rvh0000gs/T/ipykernel_62685/565452746.py\", line 15, in <module>\n    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait))\n\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pytensor/compile/function/types.py:970\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 970\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvm()\n\u001b[1;32m    971\u001b[0m         \u001b[39mif\u001b[39;00m output_subset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvm(output_subset\u001b[39m=\u001b[39moutput_subset)\n\u001b[1;32m    973\u001b[0m     )\n\u001b[1;32m    974\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m     prob \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mDeterministic(\u001b[39m'\u001b[39m\u001b[39mprob\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m pm\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mgamma[subj_id] \u001b[39m*\u001b[39m ( delay_amt\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39m(kappa[subj_id]\u001b[39m*\u001b[39mdelay_wait)) \n\u001b[1;32m     16\u001b[0m                                                                             \u001b[39m-\u001b[39m immed_amt\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39m(kappa[subj_id]\u001b[39m*\u001b[39mimmed_wait)) ))))\n\u001b[1;32m     18\u001b[0m     y_1 \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mBernoulli(\u001b[39m'\u001b[39m\u001b[39my_1\u001b[39m\u001b[39m'\u001b[39m,p\u001b[39m=\u001b[39mprob,observed\u001b[39m=\u001b[39mchoices)\n\u001b[0;32m---> 20\u001b[0m     trace_coords \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39;49msample(\u001b[39m1000\u001b[39;49m, tune\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, cores\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,target_accept\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m summary\u001b[39m=\u001b[39m az\u001b[39m.\u001b[39msummary(trace_coords,round_to\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/sampling/mcmc.py:593\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, step, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m         [kwargs\u001b[39m.\u001b[39msetdefault(k, v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m nuts_kwargs\u001b[39m.\u001b[39mitems()]\n\u001b[1;32m    592\u001b[0m     _log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mAuto-assigning NUTS sampler...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 593\u001b[0m     initial_points, step \u001b[39m=\u001b[39m init_nuts(\n\u001b[1;32m    594\u001b[0m         init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    595\u001b[0m         chains\u001b[39m=\u001b[39;49mchains,\n\u001b[1;32m    596\u001b[0m         n_init\u001b[39m=\u001b[39;49mn_init,\n\u001b[1;32m    597\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    598\u001b[0m         random_seed\u001b[39m=\u001b[39;49mrandom_seed_list,\n\u001b[1;32m    599\u001b[0m         progressbar\u001b[39m=\u001b[39;49mprogressbar,\n\u001b[1;32m    600\u001b[0m         jitter_max_retries\u001b[39m=\u001b[39;49mjitter_max_retries,\n\u001b[1;32m    601\u001b[0m         tune\u001b[39m=\u001b[39;49mtune,\n\u001b[1;32m    602\u001b[0m         initvals\u001b[39m=\u001b[39;49minitvals,\n\u001b[1;32m    603\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m initial_points \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[39m# Time to draw/evaluate numeric start points for each chain.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     ipfns \u001b[39m=\u001b[39m make_initial_point_fns_per_chain(\n\u001b[1;32m    609\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    610\u001b[0m         overrides\u001b[39m=\u001b[39minitvals,\n\u001b[1;32m    611\u001b[0m         jitter_rvs\u001b[39m=\u001b[39m\u001b[39mset\u001b[39m(),\n\u001b[1;32m    612\u001b[0m         chains\u001b[39m=\u001b[39mchains,\n\u001b[1;32m    613\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/sampling/mcmc.py:1238\u001b[0m, in \u001b[0;36minit_nuts\u001b[0;34m(init, chains, n_init, model, random_seed, progressbar, jitter_max_retries, tune, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m _log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInitializing NUTS using \u001b[39m\u001b[39m{\u001b[39;00minit\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1233\u001b[0m cb \u001b[39m=\u001b[39m [\n\u001b[1;32m   1234\u001b[0m     pm\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mCheckParametersConvergence(tolerance\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m, diff\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1235\u001b[0m     pm\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mCheckParametersConvergence(tolerance\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m, diff\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelative\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1236\u001b[0m ]\n\u001b[0;32m-> 1238\u001b[0m initial_points \u001b[39m=\u001b[39m _init_jitter(\n\u001b[1;32m   1239\u001b[0m     model,\n\u001b[1;32m   1240\u001b[0m     initvals,\n\u001b[1;32m   1241\u001b[0m     seeds\u001b[39m=\u001b[39;49mrandom_seed_list,\n\u001b[1;32m   1242\u001b[0m     jitter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mjitter\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39min\u001b[39;49;00m init,\n\u001b[1;32m   1243\u001b[0m     jitter_max_retries\u001b[39m=\u001b[39;49mjitter_max_retries,\n\u001b[1;32m   1244\u001b[0m )\n\u001b[1;32m   1246\u001b[0m apoints \u001b[39m=\u001b[39m [DictToArrayBijection\u001b[39m.\u001b[39mmap(point) \u001b[39mfor\u001b[39;00m point \u001b[39min\u001b[39;00m initial_points]\n\u001b[1;32m   1247\u001b[0m apoints_data \u001b[39m=\u001b[39m [apoint\u001b[39m.\u001b[39mdata \u001b[39mfor\u001b[39;00m apoint \u001b[39min\u001b[39;00m apoints]\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/sampling/mcmc.py:1132\u001b[0m, in \u001b[0;36m_init_jitter\u001b[0;34m(model, initvals, seeds, jitter, jitter_max_retries)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m jitter_max_retries:\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         model\u001b[39m.\u001b[39;49mcheck_start_vals(point)\n\u001b[1;32m   1133\u001b[0m     \u001b[39mexcept\u001b[39;00m SamplingError:\n\u001b[1;32m   1134\u001b[0m         \u001b[39m# Retry with a new seed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         seed \u001b[39m=\u001b[39m rng\u001b[39m.\u001b[39mrandint(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m30\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/model.py:1781\u001b[0m, in \u001b[0;36mModel.check_start_vals\u001b[0;34m(self, start)\u001b[0m\n\u001b[1;32m   1775\u001b[0m     valid_keys \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(value_names_set)\n\u001b[1;32m   1776\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m   1777\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSome start parameters do not appear in the model!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1778\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid keys are: \u001b[39m\u001b[39m{\u001b[39;00mvalid_keys\u001b[39m}\u001b[39;00m\u001b[39m, but \u001b[39m\u001b[39m{\u001b[39;00mextra_keys\u001b[39m}\u001b[39;00m\u001b[39m was supplied\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1779\u001b[0m     )\n\u001b[0;32m-> 1781\u001b[0m initial_eval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoint_logps(point\u001b[39m=\u001b[39;49melem)\n\u001b[1;32m   1783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(np\u001b[39m.\u001b[39misfinite(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m initial_eval\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m   1784\u001b[0m     \u001b[39mraise\u001b[39;00m SamplingError(\n\u001b[1;32m   1785\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInitial evaluation of model at starting point failed!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1786\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00melem\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLogp initial evaluation results:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00minitial_eval\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1788\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can call `model.debug()` for more details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1789\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/model.py:1816\u001b[0m, in \u001b[0;36mModel.point_logps\u001b[0;34m(self, point, round_vals)\u001b[0m\n\u001b[1;32m   1810\u001b[0m factors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbasic_RVs \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotentials\n\u001b[1;32m   1811\u001b[0m factor_logps_fn \u001b[39m=\u001b[39m [pt\u001b[39m.\u001b[39msum(factor) \u001b[39mfor\u001b[39;00m factor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogp(factors, \u001b[39msum\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)]\n\u001b[1;32m   1812\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m   1813\u001b[0m     factor\u001b[39m.\u001b[39mname: np\u001b[39m.\u001b[39mround(np\u001b[39m.\u001b[39masarray(factor_logp), round_vals)\n\u001b[1;32m   1814\u001b[0m     \u001b[39mfor\u001b[39;00m factor, factor_logp \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m   1815\u001b[0m         factors,\n\u001b[0;32m-> 1816\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_fn(factor_logps_fn)(point),\n\u001b[1;32m   1817\u001b[0m     )\n\u001b[1;32m   1818\u001b[0m }\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pymc/pytensorf.py:764\u001b[0m, in \u001b[0;36mPointFunc.__call__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[0;32m--> 764\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mstate)\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pytensor/compile/function/types.py:983\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvm, \u001b[39m\"\u001b[39m\u001b[39mthunks\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m         thunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvm\u001b[39m.\u001b[39mthunks[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvm\u001b[39m.\u001b[39mposition_of_error]\n\u001b[0;32m--> 983\u001b[0m     raise_with_op(\n\u001b[1;32m    984\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaker\u001b[39m.\u001b[39;49mfgraph,\n\u001b[1;32m    985\u001b[0m         node\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvm\u001b[39m.\u001b[39;49mnodes[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvm\u001b[39m.\u001b[39;49mposition_of_error],\n\u001b[1;32m    986\u001b[0m         thunk\u001b[39m=\u001b[39;49mthunk,\n\u001b[1;32m    987\u001b[0m         storage_map\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvm, \u001b[39m\"\u001b[39;49m\u001b[39mstorage_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    988\u001b[0m     )\n\u001b[1;32m    989\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[39m# old-style linkers raise their own exceptions\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pytensor/link/utils.py:535\u001b[0m, in \u001b[0;36mraise_with_op\u001b[0;34m(fgraph, node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    530\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    531\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mexc_type\u001b[39m}\u001b[39;00m\u001b[39m error does not allow us to add an extra error message\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    533\u001b[0m     \u001b[39m# Some exception need extra parameter in inputs. So forget the\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[39m# extra long error message in that case.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[39mraise\u001b[39;00m exc_value\u001b[39m.\u001b[39mwith_traceback(exc_trace)\n",
      "File \u001b[0;32m~/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/pytensor/compile/function/types.py:970\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m t0_fn \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m    968\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 970\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvm()\n\u001b[1;32m    971\u001b[0m         \u001b[39mif\u001b[39;00m output_subset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvm(output_subset\u001b[39m=\u001b[39moutput_subset)\n\u001b[1;32m    973\u001b[0m     )\n\u001b[1;32m    974\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     restore_defaults()\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1\nApply node that caused the error: AdvancedSubtensor1(gamma_log___log, TensorConstant{[0 0 0 0 0..9 9 9 9 9]})\nToposort index: 4\nInputs types: [TensorType(float64, (1,)), TensorType(uint8, (950,))]\nInputs shapes: [(1,), (950,)]\nInputs strides: [(8,), (1,)]\nInputs values: [array([0.00773022]), 'not shown']\nOutputs clients: [[Elemwise{Composite}(AdvancedSubtensor1.0, TensorConstant{[ 29.  90... 11.  89.]}, TensorConstant{(1,) of 1.0}, TensorConstant{[26. 22.  ... 20. 35.]}, TensorConstant{[ 5.  2.  ... 15. 15.]}, TensorConstant{(1,) of -1.0}, AdvancedSubtensor1.0, TensorConstant{(1,) of 1}, TensorConstant{(1,) of 0}, y_1{[1 1 0 0 1..1 1 1 1 1]})]]\n\nBacktrace when the node is created (use PyTensor flag traceback__limit=N to make it longer):\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/Users/pizarror/opt/miniconda/envs/idm_jupy/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/ts/wpzrly5j2yxb42zf5v0w5rvh0000gs/T/ipykernel_62685/565452746.py\", line 15, in <module>\n    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait))\n\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node."
     ]
    }
   ],
   "source": [
    "# We will fit a model for each subject\n",
    "\n",
    "coords = {'subject':subj_id_nb}\n",
    "with pm.Model(coords=coords) as model_coords:\n",
    "    subj_id = pm.Data('subj_id',subj_id_nb,dims='subject')\n",
    "    # Hyperparameters for k\n",
    "    # mu_kappa_hyper = pm.Beta('mu_kappa_hyper',mu=mu_kappa_hat,sigma=0.1)\n",
    "    sd_kappa_hyper = pm.Beta('sd_kappa_hyper',mu=std_kappa_hat,sigma=0.01)\n",
    "\n",
    "    # use above mean and stdev to define kappa and gamma, the posterior from the pooled is now our prior\n",
    "    # kappa = pm.Beta('kappa',mu=mu_kappa_hyper,sigma=std_kappa_hat,shape=np.size(np.unique(subj_id)))\n",
    "    kappa = pm.HalfNormal('kappa',sigma=sd_kappa_hyper,shape=np.size(np.unique(subj_id)))\n",
    "    gamma = pm.HalfNormal('gamma',sigma=0.02,shape=np.size(np.unique(subj_id)))\n",
    "    \n",
    "    prob = pm.Deterministic('prob', 1 / (1 + pm.math.exp(-gamma[subj_id] * ( delay_amt/(1+(kappa[subj_id]*delay_wait)) \n",
    "                                                                            - immed_amt/(1+(kappa[subj_id]*immed_wait)) ))))\n",
    "\n",
    "    y_1 = pm.Bernoulli('y_1',p=prob,observed=choices)\n",
    "\n",
    "    trace_coords = pm.sample(1000, tune=100, cores=2,target_accept=0.95)\n",
    "\n",
    "\n",
    "# This is how you get a nice array. Note that this returns a pandas DataFrame, not a numpy array. Indexing is totally different.\n",
    "summary= az.summary(trace_coords,round_to=10)\n",
    "fn = os.path.join(save_dir,\"BHM_model_coords.csv\")\n",
    "print('Saving to : {}'.format(fn))\n",
    "summary.to_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"Level\": [\"Basement\", \"Floor\"], \"obs_id\": np.arange(floor.size)}\n",
    "with pm.Model(coords=coords) as pooled_model:\n",
    "    floor_idx = pm.Data(\"floor_idx\", floor, dims=\"obs_id\")\n",
    "    a = pm.Normal(\"a\", 0.0, sigma=10.0, dims=\"Level\")\n",
    "\n",
    "    theta = a[floor_idx]\n",
    "    sigma = pm.Exponential(\"sigma\", 1.0)\n",
    "\n",
    "    y = pm.Normal(\"y\", theta, sigma=sigma, observed=log_radon, dims=\"obs_id\")\n",
    "\n",
    "pm.model_to_graphviz(pooled_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d5eda77765311109b2c027e144dcf58f89dd96008cdf29c2e6b03e99df71a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
